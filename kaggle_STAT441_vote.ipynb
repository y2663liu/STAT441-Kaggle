{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4","mount_file_id":"1CuCIGHirKZ2bBQevJQqVXFFcrlXP7hiD","authorship_tag":"ABX9TyMj614maBRxVQm8pmrlfn8Y"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Library:"],"metadata":{"id":"qGdsQ6rRvoCD"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from scipy.stats import mode\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import TensorDataset, DataLoader, random_split\n","import os\n","\n","from google.colab import drive"],"metadata":{"id":"xNRylIRrux0F","executionInfo":{"status":"ok","timestamp":1702948863979,"user_tz":300,"elapsed":5000,"user":{"displayName":"刘亦凡","userId":"09216365541576887674"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["# Function to apply majority vote\n","def majority_vote(row):\n","  predictions = row[1:].values\n","  return mode(predictions)[0]\n","\n","# Get all CSV file names in the current directory\n","csv_files = [file for file in os.listdir() if file.endswith('.csv')]\n","\n","# Read each CSV file and store in a list\n","dfs = []\n","for file in csv_files:\n","  df = pd.read_csv(file)\n","  if 'Predicted' in df.columns and 'ID' in df.columns:\n","    dfs.append(df)\n","\n","# Ensure there is at least one valid DataFrame\n","if not dfs:\n","  raise ValueError(\"No valid CSV files found.\")\n","\n","# Combine the predictions into a single DataFrame\n","combined_df = pd.DataFrame({'ID': dfs[0]['ID']})\n","for i, df in enumerate(dfs, start=1):\n","  combined_df[f'Pred{i}'] = df['Predicted']\n","\n","# Apply majority vote for each row\n","combined_df['Predicted'] = combined_df.apply(majority_vote, axis=1)\n","\n","# Create final DataFrame with 'ID' and majority voted predictions\n","final_df = combined_df[['ID', 'Predicted']]\n","\n","# Optionally, save the final DataFrame to a new CSV file\n","final_df.to_csv('majority_vote_predictions_combined_mix09.csv', index=False)\n"],"metadata":{"id":"wgHJdb6CYNH0","executionInfo":{"status":"ok","timestamp":1702948922385,"user_tz":300,"elapsed":39003,"user":{"displayName":"刘亦凡","userId":"09216365541576887674"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["df_old = pd.read_csv('./pre_vote/majority_vote_predictions6_2.csv')"],"metadata":{"id":"Y19YhtL0aBXn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Merge df1 and final_df on the 'ID' column\n","comparison_df = pd.merge(df_old, final_df, on='ID', how='left')\n","\n","# Compare predictions\n","# Assuming the prediction column in df1 is still named 'Predicted'\n","comparison_df['Is_Match'] = comparison_df['Predicted_x'] == comparison_df['Predicted_y']\n","\n","# View the comparison DataFrame\n","print(comparison_df.head())\n","\n","# Count the number of rows where predictions do not match\n","mismatch_count = comparison_df[comparison_df['Is_Match'] == False].shape[0]\n","\n","# Total number of rows in the DataFrame\n","total_rows = comparison_df.shape[0]\n","\n","# Calculate the proportion of mismatched rows\n","mismatch_proportion = mismatch_count / total_rows\n","\n","print(f\"Number of mismatched rows: {mismatch_count}\")\n","print(f\"Total number of rows: {total_rows}\")\n","print(f\"Proportion of mismatched rows: {mismatch_proportion:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ma7iyn3saOqb","executionInfo":{"status":"ok","timestamp":1702925439472,"user_tz":-480,"elapsed":3,"user":{"displayName":"刘亦凡","userId":"09216365541576887674"}},"outputId":"bd11e7ea-b145-4841-9115-4be984262db5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   ID  Predicted_x  Predicted_y  Is_Match\n","0   0            5            5      True\n","1   1            6            7     False\n","2   2            3            3      True\n","3   3            6            6      True\n","4   4            4            4      True\n","Number of mismatched rows: 12492\n","Total number of rows: 100000\n","Proportion of mismatched rows: 0.12\n"]}]},{"cell_type":"code","source":["# Load the CSV files\n","df1 = pd.read_csv('FFNN_200-0.5_100-0.5_50-0.5_SGD90_e70_onlyNoisy01_ordinal.csv')\n","df2 = pd.read_csv('FFNN_200-0.5_100-0.5_50-0.5_e28_noisy01_ordinal.csv')\n","df3 = pd.read_csv('FFNN_200-0.5_100-0.5_50-0.5_e35_onlyNoisy001_ordinal.csv')\n","df4 = pd.read_csv('FFNN_200-0.5_100-0.5_50-0.5_e48_onlyNoisy01_ordinal.csv')\n","df5 = pd.read_csv('FFNN_200-0.5_100-0.5_50-0.5_e55_onlyNoisy01_ordinal.csv')\n","df6 = pd.read_csv('FFNN_200-0.5_100-0.5_e30_onlyNoisy01_ordinal.csv')\n","df7 = pd.read_csv('FFNN_256-0.5_128-0.5_64-0.5_e36_onlyNoisy01_ordinal.csv')\n","df8 = pd.read_csv('FFNN_256-0.5_128-0.5_64-0.5_ordinal_noisy01.csv')\n","df9 = pd.read_csv('FFNN_256-0.5_128-0.5_64-0.5_ordinal_only_noisy01.csv')\n","\n","df10 = pd.read_csv('FFNN_128-0.5_64-0.3_32-0.3.csv')\n","df11 = pd.read_csv('FFNN_128-0.5_64-0.3_32-0.3_ordinal.csv')\n","df12 = pd.read_csv('FFNN_128-0.5_64-0.3_32-0.3_ordinal_noisy001.csv')\n","df13 = pd.read_csv('FFNN_128-0.5_64-0.3_32-0.3_ordinal_noisy01.csv')\n","df14 = pd.read_csv('FFNN_128-0.5_64-0.3_32-0.3_ordinal_only_noisy01.csv')\n","df15 = pd.read_csv('FFNN_256-0.5_128-0.5_64-0.5_e22_noisy01_ordinal.csv')\n","df16 = pd.read_csv('submission_FFNN_load1.csv')"],"metadata":{"id":"rKnGKJesw-Av"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Combine the predictions into a single DataFrame, using the 'ID' column to align them\n","combined_df_c9 = pd.DataFrame({\n","    'ID': df1['ID'],\n","    'Pred1': df1['Predicted'],\n","    'Pred2': df2['Predicted'],\n","    'Pred3': df3['Predicted'],\n","    'Pred4': df4['Predicted'],\n","    'Pred5': df5['Predicted'],\n","    'Pred6': df6['Predicted'],\n","    'Pred7': df7['Predicted'],\n","    'Pred8': df8['Predicted'],\n","    'Pred9': df9['Predicted'],\n","})\n","\n","# Function to apply majority vote\n","def majority_vote(row):\n","  predictions = row[1:].values\n","  return mode(predictions)[0]\n","\n","# Apply majority vote for each row\n","combined_df_c9['Predicted'] = combined_df_c9.apply(majority_vote, axis=1)\n","\n","# Create final DataFrame with 'ID' and majority voted predictions\n","final_df_c9 = combined_df_c9[['ID', 'Predicted']]\n","\n","# Optionally, save the final DataFrame to a new CSV file\n","final_df_c9.to_csv('majority_vote_predictions6_1.csv', index=False)"],"metadata":{"id":"Q6VroWbMc_7U"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Merge df1 and final_df on the 'ID' column\n","comparison_df_c9 = pd.merge(df_old, final_df_c9, on='ID', how='left')\n","\n","# Compare predictions\n","# Assuming the prediction column in df1 is still named 'Predicted'\n","comparison_df_c9['Is_Match'] = comparison_df_c9['Predicted_x'] == comparison_df_c9['Predicted_y']\n","\n","# View the comparison DataFrame\n","print(comparison_df_c9.head())\n","\n","# Count the number of rows where predictions do not match\n","mismatch_count = comparison_df_c9[comparison_df_c9['Is_Match'] == False].shape[0]\n","\n","# Total number of rows in the DataFrame\n","total_rows = comparison_df_c9.shape[0]\n","\n","# Calculate the proportion of mismatched rows\n","mismatch_proportion = mismatch_count / total_rows\n","\n","print(f\"Number of mismatched rows: {mismatch_count}\")\n","print(f\"Total number of rows: {total_rows}\")\n","print(f\"Proportion of mismatched rows: {mismatch_proportion:.2f}\")"],"metadata":{"id":"nMniwugfdNcS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702202284154,"user_tz":-480,"elapsed":3,"user":{"displayName":"刘亦凡","userId":"09216365541576887674"}},"outputId":"0df812d4-b7e0-4a70-b2cc-28042b663db2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   ID  Predicted_x  Predicted_y  Is_Match\n","0   0            4            5     False\n","1   1            6            6      True\n","2   2            4            3     False\n","3   3            6            6      True\n","4   4            4            4      True\n","Number of mismatched rows: 26089\n","Total number of rows: 100000\n","Proportion of mismatched rows: 0.26\n"]}]},{"cell_type":"code","source":["# Combine the predictions into a single DataFrame, using the 'ID' column to align them\n","combined_df_c16 = pd.DataFrame({\n","    'ID': df1['ID'],\n","    'Pred1': df1['Predicted'],\n","    'Pred2': df2['Predicted'],\n","    'Pred3': df3['Predicted'],\n","    'Pred4': df4['Predicted'],\n","    'Pred5': df5['Predicted'],\n","    'Pred6': df6['Predicted'],\n","    'Pred7': df7['Predicted'],\n","    'Pred8': df8['Predicted'],\n","    'Pred9': df9['Predicted'],\n","    'Pred10': df10['Predicted'],\n","    'Pred11': df11['Predicted'],\n","    'Pred12': df12['Predicted'],\n","    'Pred13': df13['Predicted'],\n","    'Pred14': df14['Predicted'],\n","    'Pred15': df15['Predicted'],\n","    'Pred16': df16['Predicted'],\n","})\n","\n","# Function to apply majority vote\n","def majority_vote(row):\n","    predictions = row[1:].values\n","    return mode(predictions)[0]\n","\n","# Apply majority vote for each row\n","combined_df_c16['Predicted'] = combined_df_c16.apply(majority_vote, axis=1)\n","\n","# Create final DataFrame with 'ID' and majority voted predictions\n","final_df_c16 = combined_df_c16[['ID', 'Predicted']]\n","\n","# Optionally, save the final DataFrame to a new CSV file\n","final_df_c16.to_csv('majority_vote_predictions6_2.csv', index=False)"],"metadata":{"id":"DXptO2WPw-VG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Merge df1 and final_df on the 'ID' column\n","comparison_df_c16 = pd.merge(df_old, final_df_c16, on='ID', how='left')\n","\n","# Compare predictions\n","# Assuming the prediction column in df1 is still named 'Predicted'\n","comparison_df_c16['Is_Match'] = comparison_df_c16['Predicted_x'] == comparison_df_c16['Predicted_y']\n","\n","# View the comparison DataFrame\n","print(comparison_df_c16.head())\n","\n","# Count the number of rows where predictions do not match\n","mismatch_count = comparison_df_c16[comparison_df_c16['Is_Match'] == False].shape[0]\n","\n","# Total number of rows in the DataFrame\n","total_rows = comparison_df_c16.shape[0]\n","\n","# Calculate the proportion of mismatched rows\n","mismatch_proportion = mismatch_count / total_rows\n","\n","print(f\"Number of mismatched rows: {mismatch_count}\")\n","print(f\"Total number of rows: {total_rows}\")\n","print(f\"Proportion of mismatched rows: {mismatch_proportion:.2f}\")"],"metadata":{"id":"dGHzCcdLw4LH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702202331271,"user_tz":-480,"elapsed":2,"user":{"displayName":"刘亦凡","userId":"09216365541576887674"}},"outputId":"20f75d2c-7dd4-4c77-cb36-74635f53f834"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   ID  Predicted_x  Predicted_y  Is_Match\n","0   0            4            5     False\n","1   1            6            6      True\n","2   2            4            3     False\n","3   3            6            6      True\n","4   4            4            4      True\n","Number of mismatched rows: 21292\n","Total number of rows: 100000\n","Proportion of mismatched rows: 0.21\n"]}]},{"cell_type":"code","source":["# Combine the predictions into a single DataFrame, using the 'ID' column to align them\n","combined_df_c3 = pd.DataFrame({\n","    'ID': df1['ID'],\n","    'Pred1': df1['Predicted'],\n","    'Pred2': df2['Predicted'],\n","    'Pred3': df3['Predicted'],\n","})\n","\n","# Function to apply majority vote\n","def majority_vote(row):\n","  predictions = row[1:].values\n","  return mode(predictions)[0]\n","\n","# Apply majority vote for each row\n","combined_df_c3['Predicted'] = combined_df_c3.apply(majority_vote, axis=1)\n","\n","# Create final DataFrame with 'ID' and majority voted predictions\n","final_df_c3 = combined_df_c3[['ID', 'Predicted']]\n","\n","# Optionally, save the final DataFrame to a new CSV file\n","final_df_c3.to_csv('majority_vote_predictions5.3.csv', index=False)"],"metadata":{"id":"DxNGzL21qEfY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Merge df1 and final_df on the 'ID' column\n","comparison_df_c3 = pd.merge(df_old, final_df_c3, on='ID', how='left')\n","\n","# Compare predictions\n","# Assuming the prediction column in df1 is still named 'Predicted'\n","comparison_df_c3['Is_Match'] = comparison_df_c3['Predicted_x'] == comparison_df_c3['Predicted_y']\n","\n","# View the comparison DataFrame\n","print(comparison_df_c3.head())\n","\n","# Count the number of rows where predictions do not match\n","mismatch_count = comparison_df_c3[comparison_df_c3['Is_Match'] == False].shape[0]\n","\n","# Total number of rows in the DataFrame\n","total_rows = comparison_df_c3.shape[0]\n","\n","# Calculate the proportion of mismatched rows\n","mismatch_proportion = mismatch_count / total_rows\n","\n","print(f\"Number of mismatched rows: {mismatch_count}\")\n","print(f\"Total number of rows: {total_rows}\")\n","print(f\"Proportion of mismatched rows: {mismatch_proportion:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ui5VIuIYqPk1","executionInfo":{"status":"ok","timestamp":1701992605521,"user_tz":-480,"elapsed":4,"user":{"displayName":"刘亦凡","userId":"09216365541576887674"}},"outputId":"7fcbb114-fa75-4b80-9f9d-51f9aeba5638"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   ID  Predicted_x  Predicted_y  Is_Match\n","0   0            4            5     False\n","1   1            6            6      True\n","2   2            4            4      True\n","3   3            6            6      True\n","4   4            4            4      True\n","Number of mismatched rows: 20482\n","Total number of rows: 100000\n","Proportion of mismatched rows: 0.20\n"]}]},{"cell_type":"markdown","source":["Load model and predict"],"metadata":{"id":"9AExcUR2c2sM"}},{"cell_type":"code","source":["class FFNN(nn.Module):\n","  def __init__(self, input_size, hidden_sizes, output_size, dropout_rates, batch_norm=False):\n","    super(FFNN, self).__init__()\n","    self.layers = nn.ModuleList()  # ModuleList to hold all layers\n","    self.hidden_sizes = hidden_sizes\n","    self.dropout_rates = dropout_rates\n","\n","    # Create layers based on the hidden_sizes and dropout_rates\n","    last_size = input_size\n","    for hidden_size, dropout_rate in zip(hidden_sizes, dropout_rates):\n","      self.layers.append(nn.Linear(last_size, hidden_size))\n","      if batch_norm:\n","        self.layers.append(nn.BatchNorm1d(hidden_size))\n","      self.layers.append(nn.Dropout(dropout_rate))\n","      last_size = hidden_size\n","\n","    # Output layer\n","    self.layers.append(nn.Linear(last_size, output_size))\n","\n","  def forward(self, x):\n","    for layer in self.layers[:-1]:\n","      if isinstance(layer, nn.Linear):\n","        x = F.relu(layer(x))\n","      else:\n","        x = layer(x)\n","    # No activation function in the last layer\n","    x = self.layers[-1](x)\n","    return x\n","\n","  def generate_filename(self):\n","    filename = \"FFNN_\" + \"_\".join(f\"{hs}-{dr}\" for hs, dr in zip(self.hidden_sizes, self.dropout_rates))\n","    return filename\n"],"metadata":{"id":"9JGzE5XReegw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_load1 = torch.load(\"FFNN_[128, 64, 32]_1_[0.5, 0.3, 0.3]_True_0001_500_wd.pth\")\n","model_load2 = torch.load(\"FFNN_[128, 64]_1_[0.5, 0.4]_True_0001_500_wd.pth\")\n","model_load3 = torch.load(\"FFNN_128-0.5_64-0.4_64-0.4_32-0.3.pth\")\n","\n","model_load1.eval()\n","model_load2.eval()\n","model_load3.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ZNtmzKNc6wZ","executionInfo":{"status":"ok","timestamp":1701888848010,"user_tz":-480,"elapsed":5630,"user":{"displayName":"刘亦凡","userId":"09216365541576887674"}},"outputId":"fc6636db-f9df-4e5d-9f68-72810933bf84"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FFNN(\n","  (layers): ModuleList(\n","    (0): Linear(in_features=2096, out_features=128, bias=True)\n","    (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=128, out_features=64, bias=True)\n","    (4): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (5): Dropout(p=0.4, inplace=False)\n","    (6): Linear(in_features=64, out_features=64, bias=True)\n","    (7): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (8): Dropout(p=0.4, inplace=False)\n","    (9): Linear(in_features=64, out_features=32, bias=True)\n","    (10): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (11): Dropout(p=0.3, inplace=False)\n","    (12): Linear(in_features=32, out_features=1, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# List to store predictions\n","predictions_avg3 = []\n","\n","with torch.no_grad():\n","  for inputs in test_standard_normalized_dataloader:\n","    inputs = inputs[0]\n","    inputs = inputs.to(device)\n","\n","    # Forward pass\n","    outputs_2 = model_load2(inputs).squeeze()\n","\n","    # Process the outputs (e.g., rounding/clamping)\n","    processed_output = torch.clamp(outputs_2.round(), 0, 7)\n","\n","    # Store the predictions\n","    predictions_load2.append(int(processed_output.cpu().item()))\n","\n","# 'predictions' now contains the processed predictions for your test dataset"],"metadata":{"id":"_AKBUj_3ewPB"},"execution_count":null,"outputs":[]}]}